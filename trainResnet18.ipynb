{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c160ead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:53.256885Z",
     "iopub.status.busy": "2024-11-06T17:27:53.256483Z",
     "iopub.status.idle": "2024-11-06T17:27:58.749660Z",
     "shell.execute_reply": "2024-11-06T17:27:58.748690Z"
    },
    "papermill": {
     "duration": 5.503435,
     "end_time": "2024-11-06T17:27:58.752015",
     "exception": false,
     "start_time": "2024-11-06T17:27:53.248580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import ast\n",
    "import json\n",
    "from PIL import Image,ImageDraw,ImageDraw2\n",
    "import  io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d489a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:58.765984Z",
     "iopub.status.busy": "2024-11-06T17:27:58.765551Z",
     "iopub.status.idle": "2024-11-06T17:27:58.769625Z",
     "shell.execute_reply": "2024-11-06T17:27:58.768713Z"
    },
    "papermill": {
     "duration": 0.013267,
     "end_time": "2024-11-06T17:27:58.771623",
     "exception": false,
     "start_time": "2024-11-06T17:27:58.758356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_dict = {}\n",
    "dec_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea840c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:58.784264Z",
     "iopub.status.busy": "2024-11-06T17:27:58.783998Z",
     "iopub.status.idle": "2024-11-06T17:27:58.806366Z",
     "shell.execute_reply": "2024-11-06T17:27:58.805560Z"
    },
    "papermill": {
     "duration": 0.030908,
     "end_time": "2024-11-06T17:27:58.808293",
     "exception": false,
     "start_time": "2024-11-06T17:27:58.777385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_files(csv):\n",
    "    \"\"\" Encode all label by name of csv_files \"\"\"\n",
    "    counter = 0\n",
    "    for fn in csv:\n",
    "        en_dict[fn[:-4].split('/')[-1].replace(' ', '_')] = counter\n",
    "        counter += 1\n",
    "        \n",
    "\n",
    "def decode_labels(label):\n",
    "    return dec_dict[label]\n",
    "\n",
    "def get_label(nfile):\n",
    "    return en_dict[nfile.replace(' ', '_')[:-4]]\n",
    "\n",
    "def get_csv(path):\n",
    "    csv_files = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('csv'):\n",
    "            csv_files.append(file)\n",
    "    return csv_files\n",
    "\n",
    "def strokes_to_arr_1Channel(arr):\n",
    "    arr = ast.literal_eval(arr)\n",
    "    x = [x_pnt for stroke in arr for x_pnt in stroke[0]]\n",
    "    y = [x_pnt for stroke in arr for x_pnt in stroke[1]]\n",
    "\n",
    "    plt.plot(x,y,color = 'black')\n",
    "    plt.axis('off')\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    plt.clf()\n",
    "    \n",
    "    image = np.array(Image.open(buf))\n",
    "    buf.close()\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = 0.2989*image[0] + 0.5870*image[1] + 0.1140*image[2]\n",
    "    image = np.ceil(image)\n",
    "    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    return image\n",
    "\n",
    "\n",
    "def strokes_to_arr_3Channels(arr):\n",
    "    arr = ast.literal_eval(arr)\n",
    "    x = [x_pnt for stroke in arr for x_pnt in stroke[0]]\n",
    "    y = [x_pnt for stroke in arr for x_pnt in stroke[1]]\n",
    "\n",
    "    plt.plot(x,y,color = 'black')\n",
    "    plt.axis('off')\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    plt.clf()\n",
    "    \n",
    "    image = np.array(Image.open(buf))\n",
    "    buf.close()\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = np.asarray([image[0],image[1],image[2]])\n",
    "    return image\n",
    "\n",
    "def validation(lossf, scoref):\n",
    "    model.eval()\n",
    "    loss, score = 0, 0\n",
    "    vlen = len(valid_loader)\n",
    "    for x, y in valid_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        loss += lossf(output, y).item()\n",
    "        score += scoref(output, y)[0].item()\n",
    "    model.train()\n",
    "    return loss/vlen, score/vlen\n",
    "\n",
    "def accuracy(output, target, topk=(3,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "def mapk(output, target, k=3):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    output (torch.Tensor): A Tensor of predicted elements.\n",
    "                           Shape: (N,C)  where C = number of classes, N = batch size\n",
    "    target (torch.int): A Tensor of elements that are to be predicted. \n",
    "                        Shape: (N) where each value is  0≤targets[i]≤C−1\n",
    "    k (int, optional): The maximum number of predicted elements\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    score (torch.float):  The mean average precision at k over the output\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(k, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        for i in range(k):\n",
    "            correct[i] = correct[i]*(k-i)\n",
    "            \n",
    "        score = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        score.mul_(1.0 / (k * batch_size))\n",
    "        return score\n",
    "    \n",
    "def squeeze_weights(m):\n",
    "        m.weight.data = m.weight.data.sum(dim=1)[:,None]\n",
    "        m.in_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df140250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:58.821191Z",
     "iopub.status.busy": "2024-11-06T17:27:58.820919Z",
     "iopub.status.idle": "2024-11-06T17:27:58.833477Z",
     "shell.execute_reply": "2024-11-06T17:27:58.832738Z"
    },
    "papermill": {
     "duration": 0.02174,
     "end_time": "2024-11-06T17:27:58.835725",
     "exception": false,
     "start_time": "2024-11-06T17:27:58.813985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv = get_csv(\"E:\\\\Project_FML\\\\train\")\n",
    "csv = sorted(csv)\n",
    "encode_files(csv)\n",
    "dec_dict = {v: k for k, v in en_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90238a72",
   "metadata": {
    "papermill": {
     "duration": 0.005429,
     "end_time": "2024-11-06T17:27:58.847909",
     "exception": false,
     "start_time": "2024-11-06T17:27:58.842480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f61936c0",
   "metadata": {
    "papermill": {
     "duration": 0.00538,
     "end_time": "2024-11-06T17:27:58.858867",
     "exception": false,
     "start_time": "2024-11-06T17:27:58.853487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN MODEL COMPUTE IS NOT ENOUGH TO TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4403238c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:58.871697Z",
     "iopub.status.busy": "2024-11-06T17:27:58.871136Z",
     "iopub.status.idle": "2024-11-06T17:27:58.876535Z",
     "shell.execute_reply": "2024-11-06T17:27:58.875765Z"
    },
    "papermill": {
     "duration": 0.013775,
     "end_time": "2024-11-06T17:27:58.878397",
     "exception": false,
     "start_time": "2024-11-06T17:27:58.864622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class StrokeDataset(Dataset):\n",
    "#     def __init__(self, csv_dir, stroke_to_numpy_func, transform=None):\n",
    "#         self.csv_dir = csv_dir\n",
    "#         self.transform = transform\n",
    "#         self.stroke_to_numpy_func = stroke_to_numpy_func\n",
    "#         self.classes = os.listdir(csv_dir)\n",
    "#         self.filepaths = []\n",
    "#         self.labels = []\n",
    "        \n",
    "#         for idx, class_name in enumerate(self.classes):\n",
    "#             csv_file = os.path.join(csv_dir, class_name)\n",
    "#             df = pd.read_csv(csv_file)\n",
    "#             for stroke in df['drawing']:\n",
    "#                 self.filepaths.append(stroke)\n",
    "#                 self.labels.append(idx)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.filepaths)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         stroke = self.filepaths[idx]\n",
    "#         label = self.labels[idx]\n",
    "        \n",
    "#         # Convert stroke to numpy array and ensure it’s grayscale (224x224)\n",
    "#         image_np = self.stroke_to_numpy_func(stroke)  # Expected output: (224, 224) for grayscale\n",
    "        \n",
    "#         # Resize if needed and convert to tensor\n",
    "#         transform_resize = T.Resize((224, 224))\n",
    "#         image = transform_resize(torch.tensor(image_np).unsqueeze(0)).float()  # (1, 224, 224)\n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "        \n",
    "#         return image, label\n",
    "\n",
    "# # Define a CNN model for grayscale input\n",
    "# class CNNModel(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(CNNModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # Input channels changed to 1\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "#         self.fc1 = nn.Linear(64 * 56 * 56, 256)  # Adjusted for 224x224 input after pooling\n",
    "#         self.fc2 = nn.Linear(256, num_classes)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(torch.relu(self.conv1(x)))\n",
    "#         x = self.pool(torch.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 64 * 56 * 56)\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e2e265b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:58.967694Z",
     "iopub.status.busy": "2024-11-06T17:27:58.967383Z",
     "iopub.status.idle": "2024-11-06T17:27:58.971248Z",
     "shell.execute_reply": "2024-11-06T17:27:58.970446Z"
    },
    "papermill": {
     "duration": 0.012405,
     "end_time": "2024-11-06T17:27:58.973117",
     "exception": false,
     "start_time": "2024-11-06T17:27:58.960712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_classes = 89\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.001\n",
    "# num_epochs = 10\n",
    "\n",
    "# dataset = StrokeDataset(csv_dir=\"/kaggle/input/train-doodle/\", stroke_to_numpy_func=strokes_to_arr)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24975b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:58.985701Z",
     "iopub.status.busy": "2024-11-06T17:27:58.985235Z",
     "iopub.status.idle": "2024-11-06T17:27:58.989378Z",
     "shell.execute_reply": "2024-11-06T17:27:58.988558Z"
    },
    "papermill": {
     "duration": 0.012474,
     "end_time": "2024-11-06T17:27:58.991299",
     "exception": false,
     "start_time": "2024-11-06T17:27:58.978825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model = CNNModel(num_classes=num_classes).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     for images, labels in dataloader:\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "    \n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0942a423",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:59.004181Z",
     "iopub.status.busy": "2024-11-06T17:27:59.003707Z",
     "iopub.status.idle": "2024-11-06T17:27:59.007340Z",
     "shell.execute_reply": "2024-11-06T17:27:59.006501Z"
    },
    "papermill": {
     "duration": 0.012188,
     "end_time": "2024-11-06T17:27:59.009306",
     "exception": false,
     "start_time": "2024-11-06T17:27:58.997118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_save_path = 'CNNmodel.pth'\n",
    "# torch.save(model.state_dict(), model_save_path)\n",
    "# print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4949a651",
   "metadata": {
    "papermill": {
     "duration": 0.005438,
     "end_time": "2024-11-06T17:27:59.020541",
     "exception": false,
     "start_time": "2024-11-06T17:27:59.015103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TRYING RESNET50 AND RESNET 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45a0f214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:59.033462Z",
     "iopub.status.busy": "2024-11-06T17:27:59.032774Z",
     "iopub.status.idle": "2024-11-06T17:27:59.040844Z",
     "shell.execute_reply": "2024-11-06T17:27:59.040122Z"
    },
    "papermill": {
     "duration": 0.01647,
     "end_time": "2024-11-06T17:27:59.042705",
     "exception": false,
     "start_time": "2024-11-06T17:27:59.026235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DoodleDataset(Dataset):\n",
    "    def __init__(self,csv,directory,function,mode,nrows,transform = None):\n",
    "        self.csv = csv\n",
    "        self.directory = directory\n",
    "        self.function = function\n",
    "        self.transform = transform\n",
    "        self.mode = mode \n",
    "        self.image = pd.read_csv(directory + csv,usecols = ['drawing'],nrows = nrows)\n",
    "        self.length = len(self.image)\n",
    "        self.image = self.image.reset_index()\n",
    "        self.label = get_label(csv)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.function(self.image['drawing'][idx])\n",
    "        label = self.label\n",
    "    \n",
    "\n",
    "        # Resize if needed and convert to tensor\n",
    "        transform_resize = T.Resize((224, 224))\n",
    "        image = transform_resize(torch.tensor(image).unsqueeze(0)).float()  # (1, 224, 224)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return image, label\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04ff77f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:59.057639Z",
     "iopub.status.busy": "2024-11-06T17:27:59.057255Z",
     "iopub.status.idle": "2024-11-06T17:27:59.062002Z",
     "shell.execute_reply": "2024-11-06T17:27:59.061049Z"
    },
    "papermill": {
     "duration": 0.016448,
     "end_time": "2024-11-06T17:27:59.065440",
     "exception": false,
     "start_time": "2024-11-06T17:27:59.048992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"E:\\\\Project_FML\\\\train\\\\\"\n",
    "csv = get_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "403aa4e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:27:59.080909Z",
     "iopub.status.busy": "2024-11-06T17:27:59.080452Z",
     "iopub.status.idle": "2024-11-06T17:28:00.747649Z",
     "shell.execute_reply": "2024-11-06T17:28:00.746685Z"
    },
    "papermill": {
     "duration": 1.67827,
     "end_time": "2024-11-06T17:28:00.750095",
     "exception": false,
     "start_time": "2024-11-06T17:27:59.071825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640410d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:28:00.766284Z",
     "iopub.status.busy": "2024-11-06T17:28:00.765245Z",
     "iopub.status.idle": "2024-11-06T17:29:40.776453Z",
     "shell.execute_reply": "2024-11-06T17:29:40.775642Z"
    },
    "papermill": {
     "duration": 100.021544,
     "end_time": "2024-11-06T17:29:40.778909",
     "exception": false,
     "start_time": "2024-11-06T17:28:00.757365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = ConcatDataset([DoodleDataset(c,path,strokes_to_arr_1Channel,'train' ,12800,None) for c in csv])\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f3d11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:29:40.794713Z",
     "iopub.status.busy": "2024-11-06T17:29:40.793882Z",
     "iopub.status.idle": "2024-11-06T17:29:40.818335Z",
     "shell.execute_reply": "2024-11-06T17:29:40.817457Z"
    },
    "papermill": {
     "duration": 0.034187,
     "end_time": "2024-11-06T17:29:40.820362",
     "exception": false,
     "start_time": "2024-11-06T17:29:40.786175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.conv1.apply(squeeze_weights)\n",
    "\n",
    "num_classes = 89\n",
    "model.fc = nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002, amsgrad=True)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5000,12000,18000], gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d52f86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:29:40.835234Z",
     "iopub.status.busy": "2024-11-06T17:29:40.834954Z",
     "iopub.status.idle": "2024-11-06T17:29:41.002263Z",
     "shell.execute_reply": "2024-11-06T17:29:41.001191Z"
    },
    "papermill": {
     "duration": 0.177128,
     "end_time": "2024-11-06T17:29:41.004350",
     "exception": false,
     "start_time": "2024-11-06T17:29:40.827222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=89, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f47b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b9f1b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:29:41.020127Z",
     "iopub.status.busy": "2024-11-06T17:29:41.019410Z",
     "iopub.status.idle": "2024-11-06T17:29:42.766348Z",
     "shell.execute_reply": "2024-11-06T17:29:42.765419Z"
    },
    "papermill": {
     "duration": 1.75687,
     "end_time": "2024-11-06T17:29:42.768415",
     "exception": false,
     "start_time": "2024-11-06T17:29:41.011545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\resnet.py:280\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x2048 and 512x89)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3598\u001b[0m, in \u001b[0;36mInteractiveShell.run_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3596\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   3597\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3598\u001b[0m         result\u001b[38;5;241m.\u001b[39merror_in_exec \u001b[38;5;241m=\u001b[39m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3599\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshowtraceback(running_compiled_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1\n",
    "lsize = len(loader)\n",
    "itr = 1\n",
    "p_itr = 1000 # print every N iteration\n",
    "model.train()\n",
    "tot = 0\n",
    "acc = 0\n",
    "tloss, score = 0, 0\n",
    "for epoch in range(epochs):\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        _,output = torch.max(output,1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tloss += loss.item()\n",
    "        acc += (output == y).sum().item()\n",
    "        tot += y.size()\n",
    "        scheduler.step()\n",
    "        if itr%p_itr==0:\n",
    "            print('Iteration {} -> Train Loss: {:.4f}, acc: {:.3f}'.format(itr, tloss/p_itr,acc/tot))\n",
    "            tloss, tot,acc = 0, 0,0\n",
    "        itr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46148f47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:29:42.784608Z",
     "iopub.status.busy": "2024-11-06T17:29:42.783844Z",
     "iopub.status.idle": "2024-11-06T17:29:42.860584Z",
     "shell.execute_reply": "2024-11-06T17:29:42.859534Z"
    },
    "papermill": {
     "duration": 0.087149,
     "end_time": "2024-11-06T17:29:42.862974",
     "exception": false,
     "start_time": "2024-11-06T17:29:42.775825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename_pth='checkpoint_resnet50.pth'\n",
    "torch.save(model.state_dict(), filename_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb1dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6016855,
     "sourceId": 9814208,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 114.732295,
   "end_time": "2024-11-06T17:29:45.313288",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-06T17:27:50.580993",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
