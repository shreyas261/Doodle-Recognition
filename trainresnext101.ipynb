{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10200,"databundleVersionId":868375,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport ast\nimport json\nfrom PIL import Image,ImageDraw,ImageDraw2\nimport  io\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport torchvision\nfrom torchvision import transforms, utils\nimport torchvision.transforms as T\nimport os\nimport cv2\nimport glob\nimport time\nimport tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"en_dict = {}\ndec_dict = {}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_files(csv):\n    \"\"\" Encode all label by name of csv_files \"\"\"\n    counter = 0\n    for fn in csv:\n        en_dict[fn[:-4].split('/')[-1].replace(' ', '_')] = counter\n        counter += 1\n        \n\ndef decode_labels(label):\n    return dec_dict[label]\n\ndef get_label(nfile):\n    return en_dict[nfile.replace(' ', '_')[:-4]]\n\ndef get_csv(path):\n    csv_files = []\n    for file in os.listdir(path):\n        if file.endswith('csv'):\n            csv_files.append(file)\n    return csv_files\n\ndef strokes_to_arr_1Channel(arr):\n    arr = ast.literal_eval(arr)\n    x = [x_pnt for stroke in arr for x_pnt in stroke[0]]\n    y = [x_pnt for stroke in arr for x_pnt in stroke[1]]\n\n    plt.plot(x,y,color = 'black')\n    plt.axis('off')\n\n    buf = io.BytesIO()\n    plt.savefig(buf, format='png')\n    buf.seek(0)\n    plt.clf()\n    \n    image = np.array(Image.open(buf))\n    buf.close()\n    image = np.transpose(image, (2, 0, 1))\n    image = 0.2989*image[0] + 0.5870*image[1] + 0.1140*image[2]\n    image = np.ceil(image)\n    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_LINEAR)\n    return image\n\n\ndef strokes_to_arr_3Channels(arr):\n    arr = ast.literal_eval(arr)\n    x = [x_pnt for stroke in arr for x_pnt in stroke[0]]\n    y = [x_pnt for stroke in arr for x_pnt in stroke[1]]\n\n    plt.plot(x,y,color = 'black')\n    plt.axis('off')\n\n    buf = io.BytesIO()\n    plt.savefig(buf, format='png')\n    buf.seek(0)\n    plt.clf()\n    \n    image = np.array(Image.open(buf))\n    buf.close()\n    image = np.transpose(image, (2, 0, 1))\n    image = np.asarray([image[0],image[1],image[2]])\n    return image\n\ndef validation(lossf, scoref):\n    model.eval()\n    loss, score = 0, 0\n    vlen = len(valid_loader)\n    for x, y in valid_loader:\n        x, y = x.to(device), y.to(device)\n        output = model(x)\n        loss += lossf(output, y).item()\n        score += scoref(output, y)[0].item()\n    model.train()\n    return loss/vlen, score/vlen\n\ndef accuracy(output, target, topk=(3,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\ndef mapk(output, target, k=3):\n    \"\"\"\n    Computes the mean average precision at k.\n    \n    Parameters\n    ----------\n    output (torch.Tensor): A Tensor of predicted elements.\n                           Shape: (N,C)  where C = number of classes, N = batch size\n    target (torch.int): A Tensor of elements that are to be predicted. \n                        Shape: (N) where each value is  0≤targets[i]≤C−1\n    k (int, optional): The maximum number of predicted elements\n    \n    Returns\n    -------\n    score (torch.float):  The mean average precision at k over the output\n    \"\"\"\n    with torch.no_grad():\n        batch_size = target.size(0)\n\n        _, pred = output.topk(k, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        for i in range(k):\n            correct[i] = correct[i]*(k-i)\n            \n        score = correct[:k].view(-1).float().sum(0, keepdim=True)\n        score.mul_(1.0 / (k * batch_size))\n        return score\n    \ndef squeeze_weights(m):\n        m.weight.data = m.weight.data.sum(dim=1)[:,None]\n        m.in_channels = 1","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = '/kaggle/input/quickdraw-doodle-recognition/train_raw/'\ncsv = get_csv(path)\ncsv = sorted(csv)\nencode_files(csv)\ndec_dict = {v: k for k, v in en_dict.items()}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DoodleDataset(Dataset):\n    def __init__(self,csv,directory,function,mode,nrows,transform = None):\n        self.csv = csv\n        self.directory = directory\n        self.function = function\n        self.transform = transform\n        self.mode = mode \n        self.image = pd.read_csv(directory + csv,usecols = ['drawing'],nrows = nrows)\n        self.length = len(self.image)\n        self.image = self.image.reset_index()\n        self.label = get_label(csv)\n        \n    def __len__(self):\n        return self.length\n            \n    def __getitem__(self, idx):\n        image = self.function(self.image['drawing'][idx])\n        label = self.label\n    \n\n        # Resize if needed and convert to tensor\n        transform_resize = T.Resize((224, 224))\n        image = transform_resize(torch.tensor(image).unsqueeze(0)).float()  # (1, 224, 224)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.mode == 'train':\n            return image, label\n        return image","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for param in model.parameters():\n    if isinstance(param,nn.Conv2d):\n        param.requires_grad = False","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = ConcatDataset([DoodleDataset(csv[c],path,strokes_to_arr_1Channel,'train' ,10000,None) for c in range(0,100)])\nloader = DataLoader(dataset, batch_size=64, shuffle=True,num_workers=0)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.conv1.apply(squeeze_weights)\n\nnum_classes = 340\nmodel.fc = nn.Linear(in_features=2048, out_features=num_classes, bias=True)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0002, amsgrad=True)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5000,12000,18000], gamma=0.5)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nmodel.to(device)\ntorch.cuda.empty_cache()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"epochs = 10\nlsize = len(loader)\nitr = 1\np_itr = 100 # print every N iteration\nmodel.train()\ntot = 0\nacc = 0\ntloss, score = 0, 0\nlast = 0\nfor epoch in range(epochs):\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        output = model(x)\n        loss = criterion(output, y)\n        _,output = torch.max(output,1)\n        loss.backward()\n        optimizer.step()\n        tloss += loss.item()\n        last = acc\n        acc += (output == y).sum().item()\n        tot += 128\n        scheduler.step()\n        if itr%p_itr==0:\n            print('Iteration {} -> Train Loss: {:.4f}, acc: {:.3f}'.format(itr, tloss/p_itr,acc/tot))\n            if acc > last:\n                last = acc\n                acc = 0\n                torch.save(model.state_dict(),\"resnext_101_\" +str(last)+\".pth\" )\n            tloss, tot,acc = 0, 0,0\n                \n        itr +=1\n        \n        ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filename_pth='resnext101.pth'\ntorch.save(model.state_dict(), filename_pth)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}