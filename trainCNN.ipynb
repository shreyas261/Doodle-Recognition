{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import ast\n",
    "import json\n",
    "from PIL import Image,ImageDraw,ImageDraw2\n",
    "import  io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = {}\n",
    "decode = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(path):\n",
    "    csv_files = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('csv'):\n",
    "            csv_files.append(file)\n",
    "    return csv_files\n",
    "\n",
    "def strokes_to_arr(arr):\n",
    "    arr = ast.literal_eval(arr)\n",
    "    x = [x_pnt for stroke in arr for x_pnt in stroke[0]]\n",
    "    y = [x_pnt for stroke in arr for x_pnt in stroke[1]]\n",
    "\n",
    "    plt.plot(x,y,color = 'black')\n",
    "    plt.axis('off')\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    plt.clf()\n",
    "    \n",
    "    image = np.array(Image.open(buf))\n",
    "    buf.close()\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = 0.2989*image[0] + 0.5870*image[1] + 0.1140*image[2]\n",
    "    image = np.ceil(image)\n",
    "    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\\\Project_FML\\\\train\\\\\"\n",
    "csv = get_csv(path)\n",
    "csv.sort()\n",
    "classes = 0\n",
    "for i in csv:\n",
    "    encode[i[:-4]] = classes\n",
    "    decode[classes] = i[:-4]\n",
    "    classes += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeDataset(Dataset):\n",
    "    def __init__(self, csv, path,stroke_to_numpy_func,nrows, transform=None):\n",
    "        self.csv_dir = csv\n",
    "        self.transform = transform\n",
    "        self.stroke_to_numpy_func = stroke_to_numpy_func\n",
    "        self.images = pd.read_csv(path + csv,usecols=['drawing'],nrows = nrows)\n",
    "        self.label = encode[csv[:-4]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images['drawing'][idx]\n",
    "        label = self.label\n",
    "\n",
    "        image = self.stroke_to_numpy_func(img)  \n",
    "        transform_resize = T.Resize((224, 224))\n",
    "        image = transform_resize(torch.tensor(image).unsqueeze(0)).float()\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 13 * 13, 256) \n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 13 * 13)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 89\n",
    "batch_size = 64\n",
    "nrows = 1000\n",
    "csv = csv[0:num_classes]\n",
    "dataset = ConcatDataset([StrokeDataset(c,path,stroke_to_numpy_func=strokes_to_arr,nrows=nrows,transform=None) for c in csv])\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "testpath = \"E:\\\\Project_FML\\\\test\\\\\"\n",
    "testdataset = ConcatDataset([StrokeDataset(c,testpath,stroke_to_numpy_func=strokes_to_arr,nrows=nrows,transform=None) for c in csv])\n",
    "testdataloader = DataLoader(testdataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "model = CNNModel(num_classes=num_classes)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 , accuracy : 0.4717167721518987 , loss : 10.008085777487937\n",
      "Epoch : 1 , accuracy : 0.6793908227848101 , loss : 1.2532217132894299\n",
      "Epoch : 2 , accuracy : 0.6819620253164557 , loss : 0.9427351249924188\n",
      "Epoch : 3 , accuracy : 0.689873417721519 , loss : 0.8468505166753938\n",
      "Epoch : 4 , accuracy : 0.7019382911392406 , loss : 0.7199833759024173\n",
      "Epoch : 5 , accuracy : 0.6962025316455697 , loss : 0.6222529724428926\n",
      "Epoch : 6 , accuracy : 0.7130142405063291 , loss : 0.5676875499230397\n",
      "Epoch : 7 , accuracy : 0.7270569620253164 , loss : 0.5000239671031131\n",
      "Epoch : 8 , accuracy : 0.727254746835443 , loss : 0.45163403319407114\n",
      "Epoch : 9 , accuracy : 0.7335838607594937 , loss : 0.3824240372905248\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "itr = 0\n",
    "for epoch in range(num_epochs):\n",
    "    acc = 0\n",
    "    p = 0\n",
    "    last = 0\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _,output = torch.max(outputs,1)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        running_loss += loss.item()\n",
    "        p += 1\n",
    "    i = 0\n",
    "    a = 0\n",
    "    for images,labels in testdataloader:\n",
    "        outputs = model(images.to(device))\n",
    "        _,output = torch.max(outputs,1)\n",
    "        a += (output == labels.to(device)).sum().item()\n",
    "        i += batch_size\n",
    "    print(\"Epoch : \" + str(epoch) + \" , accuracy : \" + str(a/i)  + \" , \" + \"loss : \" + str(running_loss/p))\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'E:\\\\Project_FML\\\\CNNmodel.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
