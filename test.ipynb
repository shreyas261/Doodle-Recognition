{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import ast\n",
    "import json\n",
    "from PIL import Image,ImageDraw,ImageDraw2\n",
    "import  io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_dict = {}\n",
    "dec_dict = {v: k for k, v in en_dict.items()}\n",
    "\n",
    "def get_csv(path):\n",
    "    csv_files = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('csv'):\n",
    "            csv_files.append(file)\n",
    "    return csv_files\n",
    "\n",
    "def strokes_to_arr_1Channel(arr):\n",
    "    arr = ast.literal_eval(arr)\n",
    "    x = [x_pnt for stroke in arr for x_pnt in stroke[0]]\n",
    "    y = [x_pnt for stroke in arr for x_pnt in stroke[1]]\n",
    "\n",
    "    plt.plot(x,y,color = 'black')\n",
    "    plt.axis('off')\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    plt.clf()\n",
    "    \n",
    "    image = np.array(Image.open(buf))\n",
    "    buf.close()\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = 0.2989*image[0] + 0.5870*image[1] + 0.1140*image[2]\n",
    "    image = np.ceil(image)\n",
    "    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    return image\n",
    "\n",
    "def encode_files(filenames):\n",
    "    \"\"\" Encode all label by name of csv_files \"\"\"\n",
    "    counter = 0\n",
    "    for fn in filenames:\n",
    "        en_dict[fn[:-4].split('/')[-1].replace(' ', '_')] = counter\n",
    "        counter += 1\n",
    "    return en_dict\n",
    "        \n",
    "\n",
    "dec_dict = {v: k for k, v in en_dict.items()}\n",
    "def decode_labels(label):\n",
    "    return dec_dict[label]\n",
    "\n",
    "def get_label(nfile):\n",
    "    \"\"\" Return encoded label for class by name of csv_files \"\"\"\n",
    "    return en_dict[nfile.replace(' ', '_')[:-4]]\n",
    "\n",
    "def strokes_to_arr_3Channels(arr):\n",
    "    arr = ast.literal_eval(arr)\n",
    "    x = [x_pnt for stroke in arr for x_pnt in stroke[0]]\n",
    "    y = [x_pnt for stroke in arr for x_pnt in stroke[1]]\n",
    "\n",
    "    plt.plot(x,y,color = 'black')\n",
    "    plt.axis('off')\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    plt.clf()\n",
    "    \n",
    "    image = np.array(Image.open(buf))\n",
    "    buf.close()\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = np.asarray([image[0],image[1],image[2]])\n",
    "    return image\n",
    "\n",
    "def validation(lossf, scoref,model,device):\n",
    "    model.eval()\n",
    "    loss, score = 0, 0\n",
    "    vlen = len(valid_loader)\n",
    "    for x, y in valid_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        loss += lossf(output, y).item()\n",
    "        score += scoref(output, y)[0].item()\n",
    "    model.train()\n",
    "    return loss/vlen, score/vlen\n",
    "\n",
    "def accuracy(output, target, topk=(3,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "def mapk(output, target, k=3):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    output (torch.Tensor): A Tensor of predicted elements.\n",
    "                           Shape: (N,C)  where C = number of classes, N = batch size\n",
    "    target (torch.int): A Tensor of elements that are to be predicted. \n",
    "                        Shape: (N) where each value is  0≤targets[i]≤C−1\n",
    "    k (int, optional): The maximum number of predicted elements\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    score (torch.float):  The mean average precision at k over the output\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(k, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        for i in range(k):\n",
    "            correct[i] = correct[i]*(k-i)\n",
    "            \n",
    "        score = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        score.mul_(1.0 / (k * batch_size))\n",
    "        return score\n",
    "    \n",
    "def squeeze_weights(m):\n",
    "        m.weight.data = m.weight.data.sum(dim=1)[:,None]\n",
    "        m.in_channels = 1\n",
    "\n",
    "def test_acc(model_path,model,testloader):\n",
    "    # model.fc = nn.Linear(512, out_features=100, bias=True)\n",
    "    # model.conv1.apply(squeeze_weights)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using : \" + str(device))\n",
    "    model.to(device)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images = images.to(device)\n",
    "            labels = torch.tensor(labels).to(device)  #temporary\n",
    "            # labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item() \n",
    "\n",
    "\n",
    "    # Step 4: Print Accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy on test set: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv(\"testfiles.csv\")\n",
    "names = names['files']\n",
    "en_dict = encode_files(names)\n",
    "dec_dict = {v: k for k, v in en_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoodleDataset(Dataset):\n",
    "    def __init__(self,csv,directory,function,mode,nrows = 0,transform = None):\n",
    "        self.csv = csv\n",
    "        self.directory = directory\n",
    "        self.function = function\n",
    "        self.transform = transform\n",
    "        self.mode = mode \n",
    "        self.image = pd.read_csv(directory + csv,usecols=['drawing'],nrows = nrows)\n",
    "        self.label = get_label(csv)\n",
    "        \n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.function(self.image['drawing'][idx])\n",
    "        label = self.label\n",
    "    \n",
    "\n",
    "        # Resize if needed and convert to tensor\n",
    "        transform_resize = T.Resize((224, 224))\n",
    "        image = transform_resize(torch.tensor(image).unsqueeze(0)).float()  # (1, 224, 224)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return image, torch.tensor(label)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = get_csv(\"E:\\\\Project_FML\\\\test\\\\\")\n",
    "csv = csv[0:10]\n",
    "testset = ConcatDataset([DoodleDataset(c,\"E:\\\\Project_FML\\\\test\\\\\",strokes_to_arr_1Channel, mode='train',nrows = 128) for c in csv])\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Resnet18_100_0.1M.pth\"\n",
    "path = \"E:\\Project_FML\\Trained_Models\\\\\" + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using : cuda\n",
      "Accuracy on test set: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_acc(path,model,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
